{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp class 1 - Week3 - nb04 - assignment",
      "provenance": [],
      "authorship_tag": "ABX9TyOSthvckw1zHDv507Bl5LS9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapmatters/coursera-nlp/blob/main/nlp_class_1_Week3_nb04_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSQJ9JMfpRaG",
        "outputId": "db6b2b11-85c3-489b-a440-2cca99eae01d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/coursera/nlp')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            " data\n",
            "'nlp class 1 - Week1 - nb01'\n",
            "'nlp class 1 - Week1 - nb02'\n",
            "'nlp class 1 - Week1 - nb03'\n",
            "'nlp class 1 - Week1 - nb04 - assignment'\n",
            "'nlp class 1 - Week2 - nb01'\n",
            "'nlp class 1 - Week2 - nb02 - assignment'\n",
            "'nlp class 1 - Week3 - nb01 - linear algebra'\n",
            "'nlp class 1 - Week3 - nb02- manipulating word embedding'\n",
            "'nlp class 1 - Week3 - nb03- PCA.ipynb'\n",
            "'nlp class 1 - Week3 - nb04 - assignment'\n",
            " py\n",
            " __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-widT1Uvq6b"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnEHCuxvgqE"
      },
      "source": [
        "# Run this cell to import packages.\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from utils import get_vectors"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S12WXVD1vuV-"
      },
      "source": [
        "def get_vectors(embeddings, words):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        embeddings: a word \n",
        "        fr_embeddings:\n",
        "        words: a list of words\n",
        "    Output: \n",
        "        X: a matrix where the rows are the embeddings corresponding to the rows on the list\n",
        "        \n",
        "    \"\"\"\n",
        "    m = len(words)\n",
        "    X = np.zeros((1, 300))\n",
        "    for word in words:\n",
        "        english = word\n",
        "        eng_emb = embeddings[english]\n",
        "        X = np.row_stack((X, eng_emb))\n",
        "    X = X[1:,:]\n",
        "    return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "00ZUPZeIv4hy",
        "outputId": "eb24177d-3705-41a7-df67-d784f67860cb"
      },
      "source": [
        "data = pd.read_csv('data/capital.csv', delimiter=',')\n",
        "data.columns = ['num','city1', 'country1', 'city2', 'country2']\n",
        "data = data[['city1', 'country1', 'city2', 'country2']]\n",
        "\n",
        "# print first five elements in the DataFrame\n",
        "data.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city1</th>\n",
              "      <th>country1</th>\n",
              "      <th>city2</th>\n",
              "      <th>country2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bangkok</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bern</td>\n",
              "      <td>Switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    city1 country1    city2     country2\n",
              "0  Athens   Greece  Bangkok     Thailand\n",
              "1  Athens   Greece  Beijing        China\n",
              "2  Athens   Greece   Berlin      Germany\n",
              "3  Athens   Greece     Bern  Switzerland\n",
              "4  Athens   Greece    Cairo        Egypt"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNqzyBrv8m_"
      },
      "source": [
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "embeddings = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary = True)\n",
        "f = open('capitals.txt', 'r').read()\n",
        "set_words = set(nltk.word_tokenize(f))\n",
        "select_words = words = ['king', 'queen', 'oil', 'gas', 'happy', 'sad', 'city', 'town', 'village', 'country', 'continent', 'petroleum', 'joyful']\n",
        "for w in select_words:\n",
        "    set_words.add(w)\n",
        "\n",
        "def get_word_embeddings(embeddings):\n",
        "\n",
        "    word_embeddings = {}\n",
        "    for word in embeddings.vocab:\n",
        "        if word in set_words:\n",
        "            word_embeddings[word] = embeddings[word]\n",
        "    return word_embeddings\n",
        "\n",
        "\n",
        "# Testing your function\n",
        "word_embeddings = get_word_embeddings(embeddings)\n",
        "print(len(word_embeddings))\n",
        "pickle.dump( word_embeddings, open( \"word_embeddings_subset.p\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmq1WcjSwYer"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}